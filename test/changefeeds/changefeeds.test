#!/usr/bin/env python

import copy, itertools, os, sys, threading, time, unittest

sys.path.append(os.path.join(os.path.dirname(__file__), os.path.pardir, 'common'))
import driver, utils

# --

lock = threading.Lock()

r = utils.import_python_driver()
dbName, tableName = utils.get_test_db_table()

# --

def synchronized(lock):
	""" Synchronization decorator """
	def wrap(f):
		def newFunction(*args, **kw):
			with lock:
				return f(*args, **kw)
		return newFunction
	return wrap

class NextWithTimeout(threading.Thread):
	'''Constantly tries to fetch the next item on an changefeed'''
	
	daemon = True
	
	feed = None
	timeout = None
	
	keepRunning = True
	latestResult = None
	
	def __enter__(self):
		return self
	
	def __exit__(self, exitType, value, traceback):
		self.keepRunning = False
	
	def __init__(self, feed, timeout=5):
		self.feed = iter(feed)
		self.timeout = timeout
		super(NextWithTimeout, self).__init__()
		self.start()
	
	def __iter__(self):
		return self
	
	def next(self):
		deadline = time.time() + self.timeout
		while time.time() < deadline:
			if self.latestResult is not None:
				if isinstance(self.latestResult, Exception):
					raise self.latestResult
				result = self.latestResult
				self.latestResult = None
				return result
			time.sleep(.05)
		else:
			raise Exception('Timed out waiting %d seconds for next item' % self.timeout)
	
	def __next__(self):
		return self.next()
	
	def run(self):
		while self.keepRunning:
			if self.latestResult is not None:
				time.sleep(.1)
				continue
			try:
				self.latestResult = next(self.feed)
				time.sleep(.5)
			except Exception as e:
				self.latestResult = e
				self.keepRunning = False

class ChangefeedsTest_Base(unittest.TestCase):
	
	# -- settings
	
	shardLevel = 2
	replicationLevel = 2
	recordsToGenerate = 1000
	samplesPerShard = 5
	
	# -- class variables
	
	cluster = None
	conn = None
	
	# --
	
	@classmethod
	def getPrimaryForShard(cls, index, table=None, db=None):
		if table is None:
			table = tableName
		if db is None:
			db = dbName
		
		serverName = r.db(dbName).table(tableName).config()['shards'].nth(index)['primary_replica'].run(cls.conn)
		for server in cls.cluster:
			if server.name == serverName:
				return server
		return None
	
	@classmethod
	def getReplicaForShard(cls, index, table=None, db=None):
		if table is None:
			table = tableName
		if db is None:
			db = dbName
		
		shardsData = r.db(dbName).table(tableName).config()['shards'].nth(index).run(cls.conn)
		replicaNames = [x for x in shardsData['replicas'] if x != shardsData['primary_replica']]
		
		for server in cls.cluster:
			if server.name in replicaNames:
				return server
		return None
	
	@classmethod
	@synchronized(lock)
	def setUp(cls):
		
		# -- short-circuit if we are already setup
		
		if cls.cluster is not None:
			return
		
		# -- start the servers
		
		cls.cluster = driver.Cluster(initial_servers=cls.shardLevel * cls.replicationLevel)
		
		server = cls.cluster[0]
		cls.conn = r.connect(host=server.host, port=server.driver_port)
		
		# -- ensure db is available
		
		if dbName not in r.db_list().run(cls.conn):
			r.db_create(dbName).run(cls.conn)
		
		# -- setup test table
		
		if tableName in r.db(dbName).table_list().run(cls.conn):
			r.db(dbName).table_drop(tableName).run(cls.conn) # ensure we have a clean table
		r.db(dbName).table_create(tableName).run(cls.conn)
		
		r.db(dbName).table(tableName).insert(r.range(1, cls.recordsToGenerate + 1).map({'id':r.row})).run(cls.conn)
		
		# - shard and replicate the table
		
		primaries = iter(cls.cluster[:cls.shardLevel])
		replicas = iter(cls.cluster[cls.shardLevel:])
		
		shardPlan = []
		for primary in primaries:
			chosenReplicas = [replicas.next().name for _ in range(0, cls.replicationLevel - 1)]
			shardPlan.append({'primary_replica':primary.name, 'replicas':[primary.name] + chosenReplicas})
		assert (r.db(dbName).table(tableName).config().update({'shards':shardPlan}).run(cls.conn))['errors'] == 0
		r.db(dbName).table(tableName).wait().run(cls.conn)
	
	@classmethod
	@synchronized(lock)
	def tearDown(cls):
		
		# verify that the servers are still running
		lastError = None
		for server in cls.cluster:
			try:
				server.check()
			except Exception as e:
				lastError = e
		if lastError is not None:
			cls.cluster = None
			cls.conn = None
			raise e
	
	def makeChanges(self, samplesPerShard=None, connections=None):
		'''make a number of minor changes to records, and return those ids'''
		
		if samplesPerShard is None:
			samplesPerShard = self.samplesPerShard
		
		if connections is None:
			connections = itertools.cycle([self.conn])
		else:
			connections = itertools.cycle(connections)
		
		changedRecordIds = []
		for lower, upper in utils.getShardRanges(connections.next(), tableName):
			
			conn = connections.next()
			sampleIds = (x['id'] for x in r.db(dbName).table(tableName).between(lower, upper).sample(samplesPerShard).run(conn))
			
			for thisId in sampleIds:
				r.db(dbName).table(tableName).get(thisId).update({'changed':True}).run(conn)
				changedRecordIds.append(thisId)
		
		changedRecordIds.sort()
		return changedRecordIds

class ChangefeedsTest_Basic(ChangefeedsTest_Base):
	'''Basic tests'''
	
	def test_simple(self):
		'''Make simple changes and ensure a single changefeed sees them'''
		
		server = self.cluster[0]
		conn = r.connect(host=server.host, port=server.driver_port)
		
		expectedCount = self.samplesPerShard * len(utils.getShardRanges(conn, tableName))
		with NextWithTimeout(r.db(dbName).table(tableName).changes().limit(expectedCount).run(conn)) as changefeed:
			expectedChangedIds = self.makeChanges()
			self.assertEqual(expectedChangedIds, sorted([x['new_val']['id'] for x in changefeed]))
	
	def test_multiple_servers(self):
		'''The same changefeed on multiple servers should get the same results'''
		
		connections = [r.connect(host=x.host, port=x.driver_port) for x in self.cluster]
		expectedCount = self.samplesPerShard * len(utils.getShardRanges(connections[0], tableName))
		changefeeds = [NextWithTimeout(r.db(dbName).table(tableName).changes().limit(expectedCount).run(x)) for x in connections]
		
		# add data across all of the connections
		
		expectedResults = self.makeChanges()
		
		# verify that all of the feeds got the expected results
		
		for i in range(len(changefeeds)):
			feedResults = sorted([x['new_val']['id'] for x in changefeeds[i]])
			self.assertEqual(feedResults, expectedResults)

class ChangefeedsTest_Destructive(ChangefeedsTest_Base):
	'''Tests that mess with the servers'''
	
	@classmethod
	@synchronized(lock)
	def tearDown(cls):
		'''For destructive tests we close down everything after each test'''
		
		lastError = None
		for server in copy.copy(cls.cluster):
			try:
				server.check_and_stop()
			except RuntimeError:
				pass
			except Exception as e:
				lastError = e
		cls.cluster = None
		cls.conn = None
		if lastError is not None:
			raise lastError
	
	def test_primary_falure(self):
		'''Test that we get the expected error when the primary replica for a shard fails for a range'''
		
		stable = self.getPrimaryForShard(0)
		sacrifice = self.getPrimaryForShard(1)
		self.assertTrue(stable != sacrifice, msg='There were not enough primary servers')
		
		conn = r.connect(host=stable.host, port=stable.driver_port)
		
		# start the changefeed
		
		changefeed = r.db(dbName).table(tableName).changes().run(conn)
		
		# add a change and retrieve it
					
		r.db(dbName).table(tableName).insert({}).run(self.conn)
		next(changefeed)
		
		# kill the sacrifice server
		
		sacrifice.process.kill()
		
		# check that we error
		
		self.assertRaises(r.RqlRuntimeError, next, changefeed)

	def test_secondary_failure(self):
		'''Test when a secondary shardholder fails for a range'''
		
		primary = self.getPrimaryForShard(0)
		replica = self.getReplicaForShard(0)
		
		conn = r.connect(host=primary.host, port=primary.driver_port)
		changesConn = r.connect(host=primary.host, port=primary.driver_port)
		
		# ensure that the replica is not also a primary
		
		self.assertTrue(replica.name not in r.db(dbName).table(tableName).config()['shards']['primary_replica'].run(conn), msg='Replica is also a primary')
		
		# start the changefeed
		
		with NextWithTimeout(r.db(dbName).table(tableName).changes().run(changesConn)) as changefeed:
		
			# add a change and retrieve it
			
			r.db(dbName).table(tableName).insert({}).run(self.conn)
			next(changefeed)
			
			# kill a secondary server
			
			replica.kill()
			
			# - add another item inside that range and make sure we still work
			
			targetRange = utils.getShardRanges(conn, table=tableName, db=dbName)[0]
			updateItem = r.db(dbName).table(tableName).between(targetRange[0], targetRange[1]).nth(0).run(conn)
			
			# with write_acks = majority
			
			self.assertTrue((r.db(dbName).table(tableName).config().update({'write_acks':'majority'}).run(conn))['errors'] == 0)
			self.assertRaises(r.RqlRuntimeError, r.db(dbName).table(tableName).get(updateItem['id']).update({'updated':True}).run, conn)
			
			# with write_acks = single
			
			self.assertTrue((r.db(dbName).table(tableName).config().update({'write_acks':'single'}).run(conn))['errors'] == 0)
			time.sleep(.1) # newton is a little slow to get this done
			r.db(dbName).table(tableName).get(updateItem['id']).update({'updated':True}).run(conn)
			next(changefeed)

	def test_connection_death(self):
		'''Test that the client handles the death of the server at the other end of the connection correctly'''
		
		stable = self.getPrimaryForShard(0)
		sacrifice = self.getPrimaryForShard(1)
		
		stable_conn = r.connect(host=stable.host, port=stable.driver_port)
		sacrifice_conn = r.connect(host=sacrifice.host, port=sacrifice.driver_port)
		
		# start the changefeed
		
		changefeed = r.db(dbName).table(tableName).changes().run(sacrifice_conn)
		
		# add a change and retrieve it
		
		r.db(dbName).table(tableName).insert({}).run(stable_conn)
		next(changefeed)
		
		# kill a primary server
		
		sacrifice.process.kill()
		
		# change an item in the stable range
		
		stableRange = utils.getShardRanges(stable_conn, table=tableName, db=dbName)[0]
		updateItem = r.db(dbName).table(tableName).between(stableRange[0], stableRange[1]).nth(0).run(stable_conn)
		r.db(dbName).table(tableName).get(updateItem['id']).update({'updated':True}).run(stable_conn)
		
		# check that we error
		
		self.assertRaises(r.RqlDriverError, next, changefeed)

# ===== main

def main():
	unittest.main()

if __name__ == '__main__':
	main()
